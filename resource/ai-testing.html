<!DOCTYPE html>
<html lang="en-GB" class="noJS" itemscope itemtype="http://schema.org/Article">
<head>
<!-- This website is written by a guy who claims to have lots of specialised technical skills, but this website only partially demonstrates them.  This website is a vehicle for about 200,000 words, please read some of them. -->
<title>LLM testing</title>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="en-GB" />
<meta name="Author" content="Owen Beresford" />
<meta name="Description" content="As LLMs are evolved rather than written, their testing is a different process to other software.  However, various reported and unexpected features show that testing is necessary.  The articles includes a LLM test plan and context information." />
<meta name="google-site-verification" content="lSgIe7Nm0H0RYQ2ktQ4vr5Jz0iYGhQd7cTWoVDg3Xss" />
<link href="/asset/favicon-32x32.png" rel="icon" type="image/png" />
<meta itemprop="name" content="LLM testing">
<meta itemprop="description" content="As LLMs are evolved rather than written, their testing is a different process to other software.  However, various reported and unexpected features show that testing is necessary.  The articles includes a LLM test plan and context information.">
<meta name="twitter:site" content="@channelOwen">
<meta name="twitter:title" content="LLM testing">
<meta name="twitter:description" content="As LLMs are evolved rather than written, their testing is a different process to other software.  However, various reported and unexpected features show that testing is necessary.  The articles includes a LLM test plan and context information.">
<meta name="twitter:creator" content="@channelOwen">
<meta property="og:title" content="LLM testing" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://owenberesford.me.uk/resource/ai-testing" />
<meta property="og:description" content="As LLMs are evolved rather than written, their testing is a different process to other software.  However, various reported and unexpected features show that testing is necessary.  The articles includes a LLM test plan and context information." />
<meta property="og:site_name" content="OwenBeresford's very wordy site" />
<meta property="article:published_time" content="8th of Dec 2024, 7:23:27" />
<meta property="article:modified_time" content="8th of Dec 2024" />
<link rel="canonical" href="https://owenberesford.me.uk/resource/ai-testing" />
<!-- the below track is just a generic cheese track, but the style fits. progressive + uplifting tone.  I do not own the rights or anything. 
TODO: magic tune selection against some index/DB -->
<meta property="og:audio" content="https://www.youtube.com/watch?v=Brl7WmHDG-E" />

<link rel="stylesheet" href="/asset/ob1.min.css" />
<script type="application/ld+json">
  {
    "@context": "https://ogp.me/ns/article#",
    "@type": "Article",
    "name": "LLM testing",
	"article:published_time":"8th of Dec 2024, 7:23:27", 
    "article:modified_time":"8th of Dec 2024",
    "article:section":"technology",

    "author": {
      "@type": "Person",
      "name": "Owen Beresford"
    }
  }
</script>
</head>
<body id="body" class="annoyingBody">
 <div class="h4_page wholeArticle">
  <div class="after_menu articleContent">
   <main id="main">
    <article>
     <div class="blocker popOverWidget addReferences">
<p class="buttonBar"> 
<a href="/resource/ai-launching-llm" class="button" title="An article looking at the LLM algorithms and related software bits." >LLM Concepts </a>
<a href="/resource/ai-dictionary" class="button" title="All the atypical language pulled out into one location, to make the other test read better." > DICTIONARY </a>
<a href="/resource/ai-retrieval-augmented-generation" class="button" title="An article looking at the RAG extension for LLM, its best practices and common implementations.">RAG Notes</a>
<a href="/resource/ai-vector-stores" class="button" title="Examines the specialised storage needed for LLM data.">Vector stores </a>
<span href="/resource/ai-testing" class="button disabled" title="This article. LLM are evolved, unlike other software.  However they still need testing.">AI testing </span>
<a href="/resource/ai-synthetic-data" class="button" title="Article that concentrates on algorithms and available libraries to create test data aka synthetic data.">Synthetic data </a>
<a href="/resource/ai-classifiers" class="button" title=" About a data management feature called classifiers, testing them and relevant algorithms.">Classifiers </a>
<a href="/resource/ai-test-prompt" class="button" title="Article to supply data on managing and testing prompts.">Test prompt </a>
<a href="/resource/ai-tune-llm" class="button" title="A detailed list of actions that that deliver better LLM based products. ">Tuning LLM </a>
</p>
<div class="lotsOfWords">

<h3 class="dontend" id="toc0"> <a href="#toc0" title="Jump to this section." > Context / intro <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>Testing LLM is an activity that I need to be able to do, but it isn't yet a strategy I have when I started writing.  If a chatbot is taking the role of a human, it should have the same responsibilities as a human.  Corporate legal depts have in some places tried to claim that as it's just software what it says isn't contractually binding <sup><a href="https://www.bbc.com/travel/article/20240222-air-canada-chatbot-misinformation-what-travellers-should-know" target="_blank">1</a></sup> <sup><a href="https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/" target="_blank">2</a></sup>.  As a UX interaction, that implies they are firing their customer support dept, and replacing it with [ . . . ].   Nothing meaningful.   This would reduce costs, but, erm, may affect customer relationships.<br />
As a zeroth question, why does common LLM tech ingest and keep random and variable data?   LLMs shouldn't treat the whole of the internet as a single flat address space.   For non-AI pieces of software, it is common practice to discard useless data.  If there was an LLM with knowledge of $english, but <em>facts</em> were only taken from the knowledge base, yes the chatbot can't recite Shakespeare to you, but is that a limitation?   If the LLM doesn't reference the internet, it won't know ‚Äúthere are no countries in Africa that start with a K‚Äù (Kenya exists), is this a limitation?   If the LLM doesn't know how law cases happen in US TV dramas, which are just fictional, (so it reads real case histories, like legal staff are supposed to) is this a limitation?   If it doesn't know that people claim they stick cheese to pizza with glue, is that a limitation?   I write $english as you may want your chatbot to speak the local Swahili not actual English.<br />
A human who 'just says things' in a work environment isn't very useful.   Neither is software that does that.   I don't know if operating chatbots have some broader context data ~ the way humans do ~ but to replace a human staff, chatbots do need to work inside a useful context.   There would need to be logic to add information from the knowledge base, but this would negatively annotate topics that contradict a filter.   For actual business process, as a human, I can talk with the US website version of a business, but I am not a US person.   I need to pay local taxes on purchases and prefer goods transacted to comply with various local safety or copyright laws.   The US company doesn't [most of the time] need to comply with my local laws, but to its local laws.   If the US goes more authoritarian on religion, and declares that no sales may occur on Sunday, the chatbot would need to know this.   But that law doesn't affect <em>me</em>.   As far as I am aware, the basic structures popularised by OpenAI do not do this type of computation.  <br />
It is vital for successful commercial delivery that stakeholders are clear about goals.  A predictable (a marketing team may override me) and reliable support agent is a good thing, and expected comms are goal driven in either direction.   There are large numbers of professions that I wouldn't have a random conversation with during their working time.   If the human is swapped for an agent, I'm still not chatting.   But a different AI agent, for example, an ‚Äúanti-loneliness agent‚Äù (with no access to contracts or money) would be better with a higher unpredictability / creativity score.   <br />
From discussion on the internet, I see that LLM products are generally less useful when possible users prefer to use a language that isn't American (ISO code en-US).   Iceland being a clear example, there are less than half a million <em>√≠slenskur</em> speakers ~ not all of whom are exporting their culture to the internet ~ and so no LLM knows <em>√≠slenskur</em> (ISO code ISL).   This is particularly jarring against the adverts touting voice as an input and output mechanism.</p>


<figure id="imageBlock" >
<img src="https://cdn.fosstodon.org/media_attachments/files/113/389/564/703/321/166/original/d6b122e8914d942a.png" alt="Screenshot of Siri support in Australia" loading="lazy" />
<figcaption > 
<strong>UPDATE:</strong> Some corporations do not think that a fairly rich country with 27 million people is a big enough target 
Source of image: Mastodon </a> <span class="button bigScreenOnly" id="biggerBtn">Expand image</span>
</figcaption>
</figure> <br />
<p>~ Australia is the ~50th most populous country.   If you don't support dialects of english, are you actually serving random US people who use their dialect rather than a ‚Äústandardised english‚Äù ~ a process feels more like Mandarin than the ‚Äúno ruleZ 'ere guv'&quot; approach that english uses. <br />
In the UK to date, the use of AI isn't mentioned by legislation, but this may change soon <sup><a href="https://www.shoosmiths.com/insights/articles/catch-me-if-you-can-the-impact-of-chatgpt-and-how-uk-ai-regulation-might-deal-with-generative-ai" target="_blank">1</a></sup> <sup><a href="https://blogs.law.ox.ac.uk/oblb/blog-post/2023/03/regulating-chatgpt-and-other-large-generative-ai-models" target="_blank">2</a></sup>.  This Science opinion paper <sup><a href="https://www.sciencedirect.com/science/article/pii/S0268401223000233" target="_blank">3</a></sup> states there is no tailoring of output ~ and the paper includes an AI summary feature in the online text.<br />
Deterministic systems are much easier to test, so maximising deterministic steps on your AI should increase quality without extra dev cost.  In the extreme, this will minimise the ‚ÄúAI‚Äù of an AI product.</p>

<p>A breakdown of areas to test (referencing <sup><a href="https://github.blog/ai-and-ml/llms/the-architecture-of-todays-llm-applications/" target="_blank">4</a></sup>).  To thoroughly test a current AI platform:</p>



<div class="row">
<div class="column">
<ul>
<li> Classifier </li>
<li> Prompt fixer </li>
<li> Embedding model </li>
<li> Vector DB </li>
<li> Vector results </li>
<li> Prompt cache </li>
<li> Verification data </li>
<li> LLM output </li>
<li> E2E UX test </li>
</ul>
</div>

<div class="column">
<ul>
<li> functional test </li>
<li> functional test </li>
<li> functional test </li>
<li> performance test </li>
<li> integration test </li>
<li> performance test </li>
<li> infrastructure </li>
<li> functional test  </li>
<li> UX + manual </li>
</ul>
</div>

<div class="column">
<ul>
<li> <a href="/resource/ai-classifiers">Classifiers article</a> </li>
<li> unit tests </li>
<li> "model testers" </li>
<li> <a href="/resource/aggregate-testing">see article</a> </li>
<li> "model testers" </li>
<li> <a href="/resource/aggregate-testing">see article</a> </li>
<li> <a href="/resource/ai-synthetic-data" >Synthetic data</a> </li>
<li> <a href="/resource/ai-test-prompt">Testing prompts</a></li>
<li> <a href="/resource/testing-epic"> one or more tools from here</a></li>
</ul>
</div>
</div>
</div>
<br /><hr /><br />
<div class="lotsOfWords">

<h3 class="dontend" id="toc1"> <a href="#toc1" title="Jump to this section." > Processes for testing <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>Random text by humans is prone to bias, but if not used as your official company voice, this isn't your problem.   If your chatbot repeats this text, then it is your problem.   Vetting the inputs for making the LLM would help.  However, assuming the LLM is purchased, you won't have control to achieve that.   Similar to the sexism test in cartoons <sup><a href="https://fanlore.org/wiki/The_Hawkeye_Initiative" target="_blank">1</a></sup> <sup><a href="https://knowyourmeme.com/memes/the-hawkeye-initiative" target="_blank">2</a></sup> ~ where one character is swapped, but not their poses or actions ~ a prompt with no identity classifiers can be stereotyped to a narrower group of people easily (by adding a few neutral tone adjectives), and if this has a large tone impact to the output of your LLM, you have a biased LLM.   Repeat for each group of people, as the LLM may not be biased against everyone.  To automate this palette of tests, compare the entirely generic first prompt output to the later prompts.   Any words that are added need to be reviewed for balance ~ noting that LLM are not deterministic.   This needs to be automated to keep the value of the LLM, my current best guess solution is Lexical libraries <sup><a href="https://en.wikipedia.org/wiki/Lexicology" target="_blank">3</a></sup> in Perl (with the tests written in Perl).  A solution sketch is to feed the word delta into Wordnet <sup><a href="https://wordnet.princeton.edu/" target="_blank">4</a></sup>, and grab the most vague / high-level term from the Wordnet results, and compare the deltas on each sample. <br />
As a test of whether the LLM can emit useful and relevant data, some people have carefully made test fixture populations.   These shouldn't be topical, or very advanced information.   The best one of these I have found so far is <sup><a href="https://www.reddit.com/r/SillyTavernAI/comments/1e1zte9/a_very_quick_and_easy_way_to_evaluate_your_llm/" target="_blank">5</a></sup>.<br />
Other people also wanted tested, therefore reliable LLM, for example <sup><a href="https://www.rungalileo.io/blog/metrics-first-approach-to-llm-evaluation" target="_blank">6</a></sup> <sup><a href="https://pkum37.medium.com/testing-of-llm-models-a-challenging-frontier-c255e09aab06" target="_blank">7</a></sup> <sup><a href="https://www.analyticsvidhya.com/blog/2023/05/how-to-evaluate-a-large-language-model-llm/" target="_blank">8</a></sup> <sup><a href="https://www.leewayhertz.com/how-to-test-llms-in-production/#How-to-test-LLMs-in-production" target="_blank">9</a></sup>.   These companies have setup frameworks for things that need testing.   A second test framework <sup><a href="https://www.codesmith.io/blog/an-introduction-to-llm-evaluation-how-to-measure-the-quality-of-llms-prompts-and-outputs" target="_blank">10</a></sup> <sup><a href="https://docs.rungalileo.io/galileo/llm-studio/prompt-inspector/choosing-your-guardrail-metrics" target="_blank">11</a></sup>, I think aimed at manual tests, sometimes including a LLM to be a test output handler.   This startup <sup><a href="https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation" target="_blank">12</a></sup> which proposes a hallucination test by repeated queries, as hallucinations do not repeat.   They also have several other tools to look at LLM.   Using an unknown quality tool to show the quality of another untested service is a risky business, and in none of the supplied examples, the second AI eliminated the need for a human operator.   I strongly suspect that the double LLM test process will have a bi-modal distribution, where it works either perfectly or terribly.   It has been demonstrated that most LLM have inline control signals.   A useful LLM cannot be popped to a lower level of context (same idea as an admin shell on a server), especially not by accident <sup><a href="https://ten10.com/blog/how-to-test-llm-based-chatbots/" target="_blank">13</a></sup>.</p>

<p>For software that takes user input and displays it to other users (e.g. social media), normally there are clearly defined rules for no hate speech, not promoting violence, only appropriate mentions to religion, no threats, no swearing etc.  I built Regexs to enforce these rules, and I'm sure many other developers have too.   If the internet is your data source, this is a bigger scope problem.  For example, there is at least one youth organisation that has ‚ÄúYT‚Äù as an abbreviation, for ‚Äúyoung...&quot; or ‚Äúyouth...&quot;, fairly innocent, and part of the legitimate function of the organisation. ...Also YouTube...  However, some pale people object to that abbreviation being used as a label for ‚Äúwhite people‚Äù.   These are normally the people labelling and stereotyping everyone else.   My most reliable and systematic solution is not to use the unmoderated internet as a data source.</p>

<p>There are quite a few laws in the US for who you employ or not employ.  Any AI process near employment decisions needs to be carefully vetted, and it's noted that the hiring company has to take responsibility rather than blame a ‚ÄúHR contractor‚Äù human or otherwise.  I refer to the John Snow labs remote conference video content, but don't know how to reference this.  The same series of videos has a nice talk on managing the implicit bias of LLM ~ this link is an entire book on one bias that is common <sup><a href="https://bookshop.org/p/books/invisible-women-data-bias-in-a-world-designed-for-men-caroline-criado-perez/15136602?ean=9781419735219" target="_blank">14</a></sup>, as it is impossible to make an LLM that is less biased than its [human] sources with current technology.</p>


<h3 class="dontend" id="toc2"> <a href="#toc2" title="Jump to this section." > Existing general test frameworks  <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<ul class="ulbasic">
    <li>Two recommended papers for testing LLM <sup><a href="https://arxiv.org/pdf/2302.06527" target="_blank">15</a></sup> <sup><a href="https://arxiv.org/pdf/2211.15458" target="_blank">16</a></sup>.  <i>When the papers mention testpilot they mean the Python one, not the JS project inside NPMJS</i>.  </li>
    <li>Python <b><a href="https://langfuse.com/" target="_blank">Langfuse</a></b> <a href="https://langfuse.com/docs" target="_blank">docs</a> and it includes some common AI already setup. </li>
    <li>Python <b>langtest</b> <a href="https://pypi.org/project/langtest/" target="_blank">src</a> <a href="https://langtest.org/docs/pages/docs/quickstart" target="_blank">docs</a>, it's built by JohnSnowLabs who also advertise via remote conferences.  The advertorial explained testing for bias in a working level of detail. </li>
    <li>mostly Python <a href="https://github.com/langchain-ai/langsmith-sdk" target="_blank">LangSmith</a> <sup><a href="https://blog.logrocket.com/langsmith-test-llms-ai-applications/" target="_blank">17</a></sup> <sup><a href="https://cobusgreyling.scribe.rip/langsmith-by-langchain-ce1742d44f24" target="_blank">18</a></sup> <sup><a href="https://scribe.rip/@kenzic/transform-your-workflow-with-langsmith-hub-a-game-changer-for-javascript-engineers-183af7cc4e31" target="_blank">19</a></sup>.  </li>
    <li>Python <b><a href="https://argilla.io/blog/synthetic-data/" target="_blank">Argilla</a></b> offer a test framework <sup><a href="https://github.com/argilla-io/distilabel" target="_blank">20</a></sup>. </li>
    <li>Alternatively Tuna <sup><a href="https://blog.langchain.dev/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/" target="_blank">21</a></sup> <sup><a href="https://scribe.rip/langchain-what-is-tuna-and-how-is-it-used-to-generate-synthetic-fine-tuning-datasets-quickly-86f2802ca593" target="_blank">22</a></sup> test framework in Python and web languages and claims to be no-code.  </li>
    <li>Testing with data-centric-tests is much cheaper and easier with a handy source of data e.g. <a href="https://owenberesford.me.uk/resource/ai-synthetic-data#">synthetic data</a>.  The last two platforms offer synthetic data.</li>
    <li><strong><a href="https://www.pangram.com/our-model/how-it-works" target="_blank">Pangram</a></strong> A platform that offers aspects of testing, I suspect they will get more features in future, </li>
    <li>A long list of lots of test tools and benchmarks <sup><a href="https://www.evidentlyai.com/llm-guide/llm-benchmarks" target="_blank">23</a></sup> </li>
</ul>

<p>Please see further articles on testing via the link bar at the top</p>

<ul class="ulbasic">
    <li>IOIO TODO add section for embeddings*</li>
    <li>IOIO TODO add section for model testers*</li>
</ul>


</div>
</div>
    </article>
   </main>
	<div id="contentGroup" class="adjacentGroup" data-group="engineering,testing" title="Use the first link to get the complete range of the group." > <p>Some similar articles in engineering </p>
<div id="groupengineering" class="adjacentList"><a class="adjacentItem button" href="/resource/group-XXX?first=engineering" aria-label="This article lists all items in engineering group.">All of <br />engineering<br /> articles </a> <noscript>Seeing this means the Adjacent feature is <strong>disabled</strong><br /> Try the full page link on the left </noscript></div>
<p>Some similar articles in testing </p>
<div id="grouptesting" class="adjacentList"><a class="adjacentItem button" href="/resource/group-XXX?first=testing" aria-label="This article lists all items in testing group.">All of <br />testing<br /> articles </a> <noscript>Seeing this means the Adjacent feature is <strong>disabled</strong><br /> Try the full page link on the left </noscript></div>
 </div>

  </div>
  <fieldset class="outer_menu articleHeader">
	<legend></legend>
	<nav>
		<div id="navBar" class="row">
			<div class="column">
				<div class="top-bar fullWidth">
					<header><h1>AI / LLM testing</h1></header>
			    	<p role="status" class="bigScreenOnly">    </p>
				</div>
				<div id="shareGroup" class="bibbles row addReading">
					<span class="allButtons"> 
						<a id="siteChartLink" class="button smallScreenOnly" href="/resource/site-chart" title="open a webpage of what articles this site holds.">Sitemap</a>
						<a id="rssLink" href="https://owenberesford.me.uk/resource/rss" title="Access the sites RSS feed."> <i class="fa fa-rss" aria-label="Open the RSS for this site." aria-hidden="true"></i><span class="sr-only">RSS</span></a> 
						<span class="button smallScreenOnly" id="shareMenuTrigger" rel="nofollow" aria-haspopup="menu" > Share </span>
						<span class="bigScreenOnly">Share: </span>
                        <a href="https://twitter.com/intent/tweet?text=I+think+this+is+important+https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-testing" title="Share this resource on your twitter account." target="_blank" class="bigScreenOnly"> <i class="fa fa-twitter" aria-label="Share this resource on your twitter account." aria-hidden="true"><span class="sr-only">Twitter</span> </i></a>
						<a href="#" id="mastoTrigger" class="masto bigScreenOnly" title="Share this article with *your* mastodon instance" aria-haspopup="dialog" >	<i class="fa fa-mastodon" aria-label="Share this article on *your* mastodon instance." aria-hidden="true"></i><span class="sr-only">Mastodon</span> </a>

						<a href="https://www.reddit.com/submit?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-testing" target="_blank" title="Share this article with your Reddit audience" class="bigScreenOnly" ><i aria-label="Share this article with your Reddit audience." class="fa fa-reddit-square" aria-hidden="true"></i><span class="sr-only">Reddit </span> </a>
						<a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-testing" target="_blank" class="bigScreenOnly" title="Share current article with your linked-in audience." ><i class="fa fa-linkedin-square" aria-hidden="true" aria-label="Share this article with your linked-in audience."></i><span class="sr-only">Linkedin</span> </a>
						<a title="Share current article with Hacker news/ Y combinator audience" target="_blank" class="bigScreenOnly" href="http://news.ycombinator.com/submitlink?u=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-testing&amp;t=LLM+testing"> <i class="fa fa-hacker-news" aria-label="Share this article with your Y combinator audience." aria-hidden="true"> </i><span class="sr-only">Hacker news</span> </a>

						<a title="Share this article with your Xing audience." href="https://www.xing.com/spi/shares/new?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-testing" target="_blank" class="bigScreenOnly" ><i class="fa fa-xing-square" aria-hidden="true" aria-label="Share this article with your Xing audience."></i><span class="sr-only">Xing</span> </a>
					</span>

					<span class="ultraSkinny bigScreenOnly"> 
						<span>Edited <time datetime="2024-12-08T07:23:16">8th of Dec 2024</time>
						</span>
						<span>Created <time datetime="2024-09-11T00:00:00" title="If the value says 03-03-2015; its wrong but that is when this project was moved to the current git project" >11th of Sep 2024</time> </span>
					</span>

				</div>
			</div>
			<dialog id="popup" class="popup1 bigScreenOnly">
				<form method="dialog" encoding="multipart/form-data" action="." name="mastoSelection"  >
					<label for="mastodonserver">your server: 
						<input id="mastodonserver" max-length="50" data-url="https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-testing" type="text" value="" placeholder="mastodon.social" />  
					</label> 
					<span id="sendMasto" class="button masto" title="Share article to *your* mastodon server">Share article now</span>
					<span class="button trimmed" id="hideMasto" title="Close popup"> <i class="fa fa-cancel" aria-hidden="true"></i> Cancel </span>
				</form>
			</dialog>
	
	<div class="bigScreenOnly column defaultLinksMenu">
		<details class="defaultLinksMenu" >
			<summary class="defaultLinksTrigger fa-" aria-haspopup="menu"> <span class="sr-only">Menu</span> </summary>

			<menu class="dfl">
			<li>Additional features</li>
<li><a href="/resource/home"><i class="fa fa-angle-left" aria-hidden="true"></i> Home</a> </li> 
<li><a href="/resource/search">Search üîé </a></li>
<li><a href="/resource/appearance">Appearance </a></li>
<li><a href="/resource/contact-me">Contact me üìû </a></li>
<li><a href="#contentGroup">üìú Similar articles</a></li>
			</menu>
		</details>
		<details open class="titleHolder"><summary >Internal links</summary><menu class="titleList">
<li><a href="#toc0">Context / intro</a></li>
<li><a href="#toc1">Processes for testing</a></li>
<li><a href="#toc2">Existing general test frameworks</a></li>
</menu>
</details><br />

	</div>

	</div>
	</nav>
</fieldset>
		</div>
 <br class="blocker" />
 <div id="biblio" style="display:none;">
    <br class="blocker" />
 </div>
 
 <footer>
  <div class="h4_footer"> 
	<div class="leftFooter"> 
		<a href="https://www.plainenglish.co.uk/services.html" target="_blank" title="They, er, don't have a service for >200,000 word sites, so no logo.">Campaign for Plain English</a><br />
		My profile: <a href="https://www.linkedin.com/in/owen-beresford-bb6ab030/" target="_blank" aria-label="my linked-in" title="Load my linked-in profile" ><i class="fixLinkedSq fa fa-linkedin-square" aria-hidden="true" aria-label="Open my linked in profile" ></i><span class="sr-only">linkedin</span></a> ~ <abbr title="This content wasn't covered in my education, as it didn't exist at that point.">Young tech</abbr>
	</div> 
	<p> Page rendered <time datetime="2024-12-08T07:23:27">8th of Dec 2024, 7:23:27</time>, Copyright &copy; 2022 Owen Beresford, <a href="https://owenberesford.me.uk/resource/contact-me">contact me</a>.  Last modified <time datetime="2024-12-08T07:23:16">8th of Dec 2024</time>.
    <p>Read the generous <a rel="license" href="https://owenberesford.me.uk/resource/licence" title="Load the license term; but not that interesting">licence terms</a>, if you feel the need, there is a <a href="https://owenberesford.me.uk/resource/privacy#" title="Load the privacy terms" >privacy here</a>.    View the <a href="https://owenberesford.me.uk/resource/site-chart#" title="Load a page showing all the articles on this site">site map</a>.  <a href="#pageMenu">Jump to menu</a>
</div>
</footer>
<script type="module" src="/asset/ob1-202406.min.mjs" ></script>  
<style>
.column { padding-left:initial; padding-right:initial; break-inside:avoid; }
.row .column ul li { display:inline-block; height:3em; text-align:center; width:100%; vertical-align:middle; align-self: center; align-items: center; }
.row .column ul li:nth-of-type(even) { background:white; }

.fullScreen { background-color:rgb(240, 255, 255); border:#333 1px solid;  display:block; position:absolute; top:10%; left:calc( 50% - 500px ); right:calc( 50% - 500px ); min-height:500px; max-height:100%; z-index:1; }
@media screen and (min-resolution: 150dpi) {
	.fullScreen { left:5%; right:5%; min-height:300px; top:5%; } 	
}
.fullScreen figcaption { text-align:center; }
.fullScreen figcaption span { margin-left:1em; }

</style>
<script type="module">
import { appendIsland, runFetch, hasBeenRun } from '/asset/ob1-202406.min.mjs'; 

function bigger() {
	const TMP=document.querySelector('#imageBlock');
	const TMP2=document.querySelector('#biggerBtn');
	if( TMP.classList.contains('fullScreen') ) {
		TMP.classList.remove('fullScreen');
		TMP2.innerText="Expand image";
	} else {
		TMP.classList.add('fullScreen');
		TMP2.innerText="Revert image";
	}
	return false;
}

function mount() {
	const TMP=document.querySelector('#biggerBtn');
	TMP.addEventListener('mousedown', bigger, {capture:true, passive:true });
	TMP.addEventListener('touchstart', bigger, {capture:true, passive:true });
}

if(hasBeenRun()===0) {
	document.pageStartup= mount;
} else {
	mount();
}

</script>
</body>
</html>