<!DOCTYPE html>
<html lang="en-GB" class="noJS" itemscope itemtype="http://schema.org/Article">
<head>
<!-- This website is written by a guy who claims to have lots of specialised technical skills, but this website only partially demonstrates them.  This website is a vehicle for about 240,000 words, please read some of them. -->
<title>Tune LLM</title>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.06" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="en-GB" />
<meta name="Author" content="Owen Beresford" />
<meta name="Description" content="A research and analysis of 12 techniques to fine-tune and improve an LLM in order to obtain a creative and generative product-making process." />
<meta name="google-site-verification" content="lSgIe7Nm0H0RYQ2ktQ4vr5Jz0iYGhQd7cTWoVDg3Xss" />
<link href="/asset/favicon-32x32.png" rel="icon" type="image/png" />
<meta itemprop="name" content="Tune LLM">
<meta itemprop="description" content="A research and analysis of 12 techniques to fine-tune and improve an LLM in order to obtain a creative and generative product-making process.">
<meta name="twitter:site" content="@channelOwen">
<meta name="twitter:title" content="Tune LLM">
<meta name="twitter:description" content="A research and analysis of 12 techniques to fine-tune and improve an LLM in order to obtain a creative and generative product-making process.">
<meta name="twitter:creator" content="@channelOwen">
<meta property="og:title" content="Tune LLM" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://owenberesford.me.uk/resource/ai-tune-llm" />
<meta property="og:description" content="A research and analysis of 12 techniques to fine-tune and improve an LLM in order to obtain a creative and generative product-making process." />
<meta property="og:site_name" content="OwenBeresford's very wordy site" />
<meta property="article:published_time" content="10th of Jun 2025, 9:54:46" />
<meta property="article:modified_time" content="Jun '25" />
<link rel="canonical" href="https://owenberesford.me.uk/resource/ai-tune-llm" />
<!-- the below track is just a generic cheese track, but the style fits. progressive + uplifting tone.  I do not own the rights or anything. 
TODO: magic tune selection against some index/DB -->
<meta property="og:audio" content="https://www.youtube.com/watch?v=Brl7WmHDG-E" />

<link rel="stylesheet" href="/asset/ob1.min.css" />
<script type="application/ld+json">
  {
    "@context": "https://ogp.me/ns/article#",
    "@type": "Article",
    "name": "Tune LLM",
	"article:published_time":"10th of Jun 2025, 9:54:46", 
    "article:modified_time":"Jun '25",
    "article:section":"technology",

    "author": {
      "@type": "Person",
      "name": "Owen Beresford"
    }
  }
</script>
</head>
<body id="body" class="annoyingBody" data-access="0">
 <div class="h4_page wholeArticle">
  <div class="after_menu articleContent">
   <main id="main">
    <article>
     <div class="blocker addReferences">
<p class="buttonBar"> 
<a href="/resource/ai-launching-llm" class="button" title="An article looking at the LLM algorithms and related software bits." >LLM Concepts </a>
<a href="/resource/ai-dictionary" class="button" title="All the atypical language pulled out into one location, to make the other test read better." > DICTIONARY </a>
<a href="/resource/ai-retrieval-augmented-generation" class="button" title="An article looking at the RAG extension for LLM, its best practices and common implementations.">RAG Notes</a>
<a href="/resource/ai-vector-stores" class="button" title="Examines the specialised storage needed for LLM data.">Vector stores </a>
<a href="/resource/ai-synthetic-data" class="button" title="Article that concentrates on algorithms and available libraries to create test data aka synthetic data.">Synthetic </a>
<a href="/resource/ai-test-prompt" class="button" title="Article to supply data on managing and testing prompts.">Test prompt </a>
<a href="/resource/ai-classifiers" class="button" title=" About a data management feature called classifiers, testing them and relevant algorithms.">Classifiers </a>
<a href="/resource/ai-testing" class="button" title="LLM are evolved, unlike other software.  However they still need testing.">AI testing </a>
<span href="/resource/ai-tune-llm" class="button disabled" title="This article. A detailed list of actions that that deliver better LLM based products.">Tuning LLM </span>
</p>
<div class="lotsOfWords">
<div class="pullout">
<p>This text is very focused on “product creation”.  If that is your current goal, this contains a large volume of maths  (as part of my LLM study).</p>


</div>

<h3 class="dontend" id="toc0"> <a href="#toc0" title="Jump to this section." > Context / intro <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>As a statement about software interactions, a LLM-based platform can: measure, predict, recommend, create (I am roughly quoting a lecture by OSDC pulled from Youtube).   The basic approach has different levels of ability at each behaviour.  Some hype by an AI company <sup><a href="https://situational-awareness.ai/from-gpt-4-to-agi/" target="_blank">1</a></sup> ~ I would be interested in the same output with a constant amount of hardware, to show the software improvements, rather than budget improvements.   Power-scaling notes with good graphs <sup><a href="https://angelxuanchang.github.io/nlp-class/assets/lecture-slides/scaling.pdf" target="_blank">2</a></sup> ~ this is a 50 page PDF &amp; it loads slowly.   To set expectations, learning is not a smooth rate of change in many situations <sup><a href="https://www.fast.ai/posts/2023-09-04-learning-jumps/" target="_blank">3</a></sup> <sup><a href="https://arxiv.org/abs/1712.09913" target="_blank">4</a></sup>.   A systematic review of LLM and handling of them (43 pages) <sup><a href="https://arxiv.org/pdf/2402.06196" target="_blank">5</a></sup>. <br />
When you buy access to an off-the-shelf LLM, it will likely need tuning.   The process to build an LLM is composed of vast amounts of Vector building from source content, but OpenAI seem to use less productisation than I would use.   There are more dedicated and contextual AI, which seems a more valuable route to go along.  Organisations with deep pockets can make their own LLM, but that does seem a very large investment (roughly the same a building your own roads, rather than using the national ones).   According to <sup><a href="https://scalexm.ai/storage/2023/10/White-Paper-LLM.pdf" target="_blank">6</a></sup>, OpenAI have spent over 100,000,000.00 USD on renting cloud servers (this number wasn't given with a timespan).  There is a leaked breakdown <sup><a href="https://medium.com/version-1/running-your-own-dedicated-openai-instance-60a93555dbd0" target="_blank">7</a></sup> with time.  A book on tuning a GPT model <sup><a href="https://sebastianraschka.com/blog/2024/building-a-gpt-style-llm-classifier.html" target="_blank">8</a></sup><br />
From a standard LLM, there is a list of techniques that have been developed to improve relevance of the output.   Depending on your AI vendor, these will already be present.   However, an LLM will need configuration to align with your product.   I analyse a number of hyperparameters, however Cohere do not use that term <sup><a href="https://cohere.com/blog/llm-parameters-best-outputs-language-ai" target="_blank">9</a></sup>, but reference diagrams are good.  Probably the first technical process is adding <a href="https://owenberesford.me.uk/resource/ai-testing#">unit tests</a> on the LLM, but that is outside of scope for this document.   The outputs can be adjusted by appending to the “known data” for the initial generation, adding a <a href="https://owenberesford.me.uk/resource/ai-retrieval-augmented-generation#">RAG</a> as a parallel data source or thirdly by adjusting the operating context.   I think the first option requires renting your own LLM software model (not cheap) from the LLM vendor.   Or theoretically buying the Vendor (as you are Microsoft) would also work.  <br />
Hopefully it is clear that “prompting” isn't “training” <sup><a href="https://towardsdatascience.com/different-ways-of-training-llms-c57885f388ed" target="_blank">10</a></sup> ~ I absorbed this from the maths, and want to be clear.  The difference between self-directed learning and directed learning (the second requires a human observer) is important.   <strong>The majority of the technical steps listed above can be downloaded from Pipyi, or Jupyterlabs</strong>, but it's “left as an exercise for the reader” to check that the data-flow lines up with your current iteration.</p>


<div class="pullout2">
<p>Please read this memo from a Google employee <sup><a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither" target="_blank">1</a></sup>, <strong>released as Anon</strong>.  They state that having a really big LLM no longer offers much benefit, and does make the model slower to train and respond.   Large LLM do use more power.</p>


</div>

<h3 class="dontend" id="toc1"> <a href="#toc1" title="Jump to this section." > Techniques available <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>

<div class="pullout">
<p>Loud note: this is a fast moving field, notes published before 2023 do not reflect today's products.  See some nice graphs <sup><a href="https://artificialanalysis.ai/models/gpt-4o-2024-08-06" target="_blank">1</a></sup>.</p>


</div>
<p>There are quite a few algorithms that can be used for tuning (I list 19 in the introduction article), and the tuning process seems to be applicable to any LLM.   I'm not sure if lots of different tuning can be stacked on top of each other (research here?).  The tuning step can deliver:</p>

<ul class="ulbasic">
    <li>The addition of data stored in a different format (e.g. a RAG, or DB results) <sup><a href="https://github.blog/ai-and-ml/llms/customizing-and-fine-tuning-llms-what-you-need-to-know/" target="_blank">1</a></sup> <sup><a href="https://www.acorn.io/resources/learning-center/fine-tuning-llm" target="_blank">2</a></sup> <sup><a href="https://deepchecks.com/how-to-test-llm-applications-before-releasing-to-production/" target="_blank">3</a></sup>.  This improves the results.</li>
    <li>Changing the LLM storage so the LLM will fit on a smaller device e.g. the 4bit quantisation ~ <i>although this example has loss of precision</i>.</li>
    <li>Retraining the LLM to value an extra set of data, absent from the first number crunching (e.g. data after 2021).</li>
    <li>[By non-defined process] splitting the LLM into different 'experts' of a narrower domain <sup><a href="https://developer.nvidia.com/blog/applying-mixture-of-experts-in-llm-architectures/" target="_blank">4</a></sup>, look at Mixtral in Huggingface <sup><a href="https://huggingface.co/docs/transformers/model_doc/mixtral" target="_blank">5</a></sup>.  Possibly the most practical method to train your own LLM from scratch, so choosing the initial data sets.   <i>TODO: find out</i>.</li>
    <li>Applying Attention analysis so the output makes mores sense <sup><a href="https://medium.com/@malachy.moran/llm-reading-list-understanding-attention-is-all-you-need-part-i-4cba140bd541" target="_blank">6</a></sup> <sup><a href="https://medium.com/@harikapanuganty/from-words-to-vectors-inside-the-llm-transformer-architecture-50275c354bc4" target="_blank">7</a></sup> and will probably be present by default.   </li>
    <li>Having a strong Natural-Language-Processing process for step 0, therefore making everything <i>afterwards</i> less like dumb data, and more like structured information.  </li>
    <li>Applying Natural-Language-Processing [1] to generate a more abstract “context prompt” to go with the users prompt, so the LLM has a better prompt to work with (this is a version of Step back prompting).</li>
    <li>Setting the Temperature value carefully, with large amounts of testing.</li>
    <li>Given “assembled” agents / LLM, there is now a stable way to integrate the results <sup><a href="https://huggingface.co/blog/mlabonne/merge-models" target="_blank">8</a></sup>.</li>
    <li>All the above steps, with careful testing.</li>
    <li>For any type of B2B product, and many types of B2C where damage is possible such as Medicine, following a damage-avoiding strategy is essential e.g. <sup><a href="https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext" target="_blank">9</a></sup> </li>
    <li>There should be some sort of specific expert for basic arithmetic operations, maybe using a regex to detect the “answer this basic sum” question, reference some nice graph I saw of social media but don't have a proper reference for (against chat GPT 4o, August edition).</li>
    <li>MAYBE DELETE Embeddings aren't a topic on the rest of this article, however <sup><a href="https://datasciencedojo.com/blog/embeddings-and-llm/" target="_blank">10</a></sup>.</li>
</ul>


</div>
<br /><hr /><br />
<div class="lotsOfWords">
<p>Note: mobiles have had “generate the next word in a text/SMS” for a long time, and they achieved this initially on very sparse hardware.   Siri by Apple inc uses a remote voice-clip to process text, and has been running this for many years.   These are examples of simple and narrow “AI”, that people don't notice.   Whilst I was trying to work out how to tune an LLM, I pulled up the following intro references: an obvious long list of business sectors that could use a tuned LLM <sup><a href="https://www.turing.com/resources/finetuning-large-language-models" target="_blank">1</a></sup>.   For people with no experience building integrations, this <sup><a href="https://writer.com/blog/how-to-evaluate-generative-ai-llm-vendors/" target="_blank">2</a></sup> covers the administration needed to build a successful business process, although it is formatted to fit in power point slides.  <br />
Apple have released a proper OSS LLM (that is, it includes its source data) <sup><a href="https://machinelearning.apple.com/research/openelm" target="_blank">3</a></sup> <sup><a href="https://arxiv.org/html/2404.14619v2" target="_blank">4</a></sup> <sup><a href="https://venturebeat.com/ai/apple-shows-off-open-ai-prowess-new-models-outperform-mistral-and-hugging-face-offerings/" target="_blank">5</a></sup> <a href="https://huggingface.co/collections/apple/core-ml-gallery-models-666b66ca4e6657b7d179bc42" target="_blank">src</a>.   A second OSS LLM library <sup><a href="https://llm.datasette.io/en/stable/" target="_blank">6</a></sup> (This second one doesn't have data attached).   List some processes that people have used to tune an LLM <sup><a href="https://arxiv.org/html/2408.13296v1" target="_blank">7</a></sup>.   Feature generation <sup><a href="https://arxiv.org/pdf/2406.03505" target="_blank">8</a></sup>.</p>

<p>I have made software that will emit a random response a percentage of the time, from a fixed list of options, to make it less dull to use.   This is NOT AI but better UX, and increases delight for tired people.   If you take the title “prompt engineer”, I think some learning in Psychology is important.</p>

<p>Another approach to tuning would be a <strong>Neuro-Symbolic</strong> approach, on the surface this doesn't use Vectors.  Please see XXX IOIO when I have written it.</p>

<hr />
<p>[1] NLP is sometimes 'natural language programming', 'natural language processing' and 'natural language parsing', but these cover the same area.</p>


<h3 class="dontend" id="toc2"> <a href="#toc2" title="Jump to this section." > Value prop  <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>A tuned LLM will create the appropriate content a much higher percentage of the time, and is likely to use less hardware resources.  This means it is a better product.  Compared to a base 3rd party LLM, your tuned one may add more features, and deliver better.  Tuning can reduce your hardware requirements, so reduce [excessive for OpenAI] running costs.<br />
An LLM trained for translation <sup><a href="https://arxiv.org/pdf/2302.09210" target="_blank">9</a></sup> as an example of derived value.  Some further carefully tuned models <sup><a href="https://blog.jetbrains.com/ai/2025/02/why-and-how-jetbrains-built-mellum-the-llm-designed-for-code-completion/" target="_blank">10</a></sup> <sup><a href="https://www.theregister.com/2025/01/07/ai_can_write_improved_code_research/" target="_blank">11</a></sup> <sup><a href="https://www.techradar.com/computing/artificial-intelligence/best-large-language-models-llms-for-coding" target="_blank">12</a></sup></p>


<aside>
<blockquote site="https://fosstodon.org/@kate">
<p>impact of good tuning is about this model: <br />
Quote:</p>

<ul class="ulbasic">
    <li>OLD it takes a human 20min to write an email, </li>
    <li>NEW it takes a few seconds for a LLM to do this, with a single draft</li>
    <li>However power used<ul class="ulbasic">
        <li>OLD [my local PCs] take 200w for all equipment, so 60Wh for that time</li>
        <li>NEW [internet numbers] 3kWh per average prompt (XXX add reference)</li>
    </ul></li>
    <li>Thus LLM uses 50 times more power, but much faster PER PROMPT.   </li>
    <li>Users often need multiple prompts, especially on more complex “actual problems”.</li>
    <li>UPDATE: Deepseek needs numbers inputted for power used</li>
</ul>


</blockquote>
</aside>
</div>
<br /><br />
</div>
    </article>
   </main>
	<div id="contentGroup" class="adjacentWidget" data-group="engineering" title="Use the first link to get the complete range of the group." > <p>Some similar articles in engineering </p>
<div id="groupengineering" class="adjacentList"><a class="adjacentItem button" href="/resource/group-XXX?first=engineering" aria-label="This article lists all items in engineering group.">All of <br />engineering<br /> articles </a> <noscript>Seeing this means the Adjacent feature is <strong>disabled</strong><br /> Try the full page link on the left </noscript></div>
 </div>

  </div>
  <fieldset class="articleHeader">
	<legend></legend>
	<nav id="navBar" class="row">
			<div class="column">
				<div class="top-bar fullWidth">
					<header><h1>Tune and Improve LLM</h1></header>
			    	<p role="status" class="bigScreenOnly">    </p>
				</div>
				<div id="shareGroup" class="metaWidget row addReading">
					<span class="SMshareWidget"> 
						<a id="siteChartLink" class="button smallScreenOnly" href="/resource/site-chart" title="open a webpage of what articles this site holds.">Sitemap</a>
						<a id="rssLink" href="https://owenberesford.me.uk/resource/rss" title="Access the sites RSS feed."> <i class="fa fa-rss" aria-label="Open the RSS for this site." aria-hidden="true"></i><span class="sr-only">RSS</span></a> 
						<span class="button smallScreenOnly" id="shareMenuTrigger" rel="nofollow" aria-haspopup="menu" > Share </span>
						<span class="bigScreenOnly">Share: </span>
                        <a href="https://twitter.com/intent/tweet?text=I+think+this+is+important+https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" title="Share this resource on your twitter account." target="_blank" class="bigScreenOnly"> <i class="fa fa-twitter" aria-label="Share this resource on your twitter account." aria-hidden="true"></i><span class="sr-only">Twitter</span></a>
						<a href="#" id="mastoTrigger" class="masto bigScreenOnly" title="Share this article with *your* mastodon instance" aria-haspopup="dialog" >	<i class="fa fa-mastodon" aria-label="Share this article on *your* mastodon instance." aria-hidden="true"></i><span class="sr-only">Mastodon</span> </a>
						<a href="https://www.reddit.com/submit?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" target="_blank" title="Share this article with your Reddit audience" class="bigScreenOnly" ><i aria-label="Share this article with your Reddit audience." class="fa fa-reddit-square" aria-hidden="true"></i><span class="sr-only">Reddit </span> </a>
						<a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" target="_blank" class="bigScreenOnly" title="Share current article with your linked-in audience." ><i class="fa fa-linkedin-square" aria-hidden="true" aria-label="Share this article with your linked-in audience."></i><span class="sr-only">Linkedin</span> </a>
						<a title="Share current article with Hacker news/ Y combinator audience" target="_blank" class="bigScreenOnly" href="http://news.ycombinator.com/submitlink?u=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm&amp;t=Tune+LLM"> <i class="fa fa-hacker-news" aria-label="Share this article with your Y combinator audience." aria-hidden="true"> </i><span class="sr-only">Hacker news</span> </a>
						<a title="Share this article with your Xing audience." href="https://www.xing.com/spi/shares/new?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" target="_blank" class="bigScreenOnly" ><i class="fa fa-xing-square" aria-hidden="true" aria-label="Share this article with your Xing audience."></i><span class="sr-only">Xing</span> </a>
					</span>

					<span class="ultraSkinny bigScreenOnly"> 
						<span>Edited <time title="Page edited on 2025-06-10T09:54:33" datetime="2025-06-10T09:54:33">Jun '25</time>
						</span>
						<span>Created <time datetime="2024-09-14T00:00:00" title="If the value says 03-03-2015; its wrong but that is when this project was moved to the current git project" >Sep '24</time> </span>
					</span>

				</div>
			</div>
			<dialog id="popup" class="mastodonWidget bigScreenOnly">
				<form method="dialog" enctype="multipart/form-data" action="." name="mastoSelection"  >
					<label for="mastodonserver">your server: 
						<input id="mastodonserver" maxlength="50" data-url="https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" type="text" value="" placeholder="mastodon.social" />  
					</label> 
					<span id="sendMasto" class="button masto" title="Share article to *your* mastodon server">Share article now</span>
					<span class="button trimmed" id="hideMasto" title="Close popup"> <i class="fa fa-cancel" aria-hidden="true"></i> Cancel </span>
				</form>
			</dialog>
	
	<div class="bigScreenOnly column linksWidget">
		<details class="linksWidget" id="pageMenu">
			<summary class="defaultLinksTrigger fa-" aria-haspopup="menu"> <span class="sr-only">Menu</span> </summary>

			<menu class="dfl">
			<li>Additional features</li>
<li><a href="/resource/home"><i class="fa fa-angle-left" aria-hidden="true"></i> Home</a> </li> 
<li><a href="/resource/search">Search 🔎 </a></li>
<li><a href="/resource/appearance">Appearance </a></li>
<li><a href="/resource/contact-me">Contact me 📞 </a></li>
<li><a href="#contentGroup">📜 Similar articles</a></li>
			</menu>
		</details>
		<details open class="headingsWidget"><summary class="fa-"><div>Chapters</div></summary><menu class="titleList">
<li><a href="#toc0">Context / intro</a></li>
<li><a href="#toc1">Techniques available</a></li>
<li><a href="#toc2">Value prop</a></li>
</menu>
</details><br />

	</div>
	<!-- /div -->
	</nav>
</fieldset>
 </div> 
 <div id="biblio" style="display:none;">
    <br class="blocker" />
 </div>
 <footer class="row footWidget"> 
	<div class="column leftFooter"> 
		<a href="https://www.plainenglish.co.uk/services.html" target="_blank" title="They, er, don't have a service for >200,000 word sites, so no logo.">Campaign for Plain English</a><br />
		My profile: <a href="https://www.linkedin.com/in/owen-beresford-bb6ab030/" target="_blank" aria-label="my linked-in" title="Load my linked-in profile" ><i class="fixLinkedSq fa fa-linkedin-square" aria-hidden="true" aria-label="Open my linked in profile" ></i><span class="sr-only">linkedin</span></a> ~ <abbr title="This content wasn't covered in my education, as it didn't exist at that point.">Young tech</abbr>
	</div> 
	<div class="column bigColumn">
		<p> Page rendered <time title="Page rendered on 2025-06-10T09:54:46" datetime="2025-06-10T09:54:46">10th of Jun 2025, 9:54:46</time>, Copyright &copy; 2022 Owen Beresford, <a href="https://owenberesford.me.uk/resource/contact-me">contact me</a>.  Last modified <time title="Page modified on 2025-06-10T09:54:33" datetime="2025-06-10T09:54:33">Jun '25</time>.
	    <p>Read the generous <a rel="license" href="https://owenberesford.me.uk/resource/licence" title="Load the license term; but not that interesting">licence terms</a>, if you feel the need, there is a <a href="https://owenberesford.me.uk/resource/privacy#" title="Load the privacy terms" >privacy here</a>.    View the <a href="https://owenberesford.me.uk/resource/site-chart#" title="Load a page showing all the articles on this site">site map</a>.  <a href="#pageMenu">Jump to menu</a>
	</div>
 </footer>
<script type="module" src="/asset/ob1-202406.min.mjs" ></script>  

</body>
</html>