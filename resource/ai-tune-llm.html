<!DOCTYPE html>
<html lang="en-GB" class="noJS" itemscope itemtype="http://schema.org/Article">
<head>
<!-- This website is written by a guy who claims to have lots of specialised technical skills, but this website only partially demonstrates them.  This website is a vehicle for about 200,000 words, please read some of them. -->
<title>Tune LLM</title>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="en-GB" />
<meta name="Author" content="Owen Beresford" />
<meta name="Description" content="A research and analysis of 12 techniques to fine tune and improve an LLM in order to obtain a creative and generative product creation process." />
<meta name="google-site-verification" content="lSgIe7Nm0H0RYQ2ktQ4vr5Jz0iYGhQd7cTWoVDg3Xss" />
<link href="/asset/favicon-32x32.png" rel="icon" type="image/png" />
<meta itemprop="name" content="Tune LLM">
<meta itemprop="description" content="A research and analysis of 12 techniques to fine tune and improve an LLM in order to obtain a creative and generative product creation process.">
<meta name="twitter:site" content="@channelOwen">
<meta name="twitter:title" content="Tune LLM">
<meta name="twitter:description" content="A research and analysis of 12 techniques to fine tune and improve an LLM in order to obtain a creative and generative product creation process.">
<meta name="twitter:creator" content="@channelOwen">
<meta property="og:title" content="Tune LLM" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://owenberesford.me.uk/resource/ai-tune-llm" />
<meta property="og:description" content="A research and analysis of 12 techniques to fine tune and improve an LLM in order to obtain a creative and generative product creation process." />
<meta property="og:site_name" content="OwenBeresford's very wordy site" />
<meta property="article:published_time" content="7th of Oct 2024, 22:20:59" />
<meta property="article:modified_time" content="7th of Oct 2024" />
<link rel="canonical" href="https://owenberesford.me.uk/resource/ai-tune-llm" />
<!-- the below track is just a generic cheese track, but the style fits. progressive + uplifting tone.  I do not own the rights or anything. 
TODO: magic tune selection against some index/DB -->
<meta property="og:audio" content="https://www.youtube.com/watch?v=Brl7WmHDG-E" />

<link rel="stylesheet" href="/asset/ob1.min.css" />
<script type="application/ld+json">
  {
    "@context": "https://ogp.me/ns/article#",
    "@type": "Article",
    "name": "Tune LLM",
	"article:published_time":"7th of Oct 2024, 22:20:59", 
    "article:modified_time":"7th of Oct 2024",
    "article:section":"technology",

    "author": {
      "@type": "Person",
      "name": "Owen Beresford"
    }
  }
</script>
</head>
<body id="body" class="annoyingBody">
 <div class="h4_page wholeArticle">
  <div class="after_menu articleContent">
   <main id="main">
    <article>
     <div class="blocker addReferences">
<p class="buttonBar"> 
<a href="/resource/ai-launching-llm" class="button" title="An article looking at the LLM algorithms and related software bits." >LLM Concepts </a>
<a href="/resource/ai-dictionary" class="button" title="All the atypical language pulled out into one location, to make the other test read better." > DICTIONARY </a>
<a href="/resource/ai-retrieval-augmented-generation" class="button" title="An article looking at the RAG extension for LLM, its best practices and common implementations.">RAG Notes</a>
<a href="/resource/ai-vector-stores" class="button" title="Examines the specialised storage needed for LLM data.">Vector stores </a>
<a href="/resource/ai-synthetic-data" class="button" title="Article that concentrates on algorithms and available libraries to create test data aka synthetic data.">Synthetic </a>
<a href="/resource/ai-test-prompt" class="button" title="Article to supply data on managing and testing prompts.">Test prompt </a>
<a href="/resource/ai-testing" class="button" title="LLM are evolved, unlike other software.  However they still need testing.">AI testing </a>
<span href="/resource/ai-tune-llm" class="button disabled" title="This article. A detailed list of actions that that deliver better LLM based products.">Tuning LLM </span>
</p>
<div class="lotsOfWords">
<div class="pullout">
<p>This text is very focused on “product creation”.  If that is not your current goal, this is a large volume of maths to no gain (this is an LLM study).</p>


</div>

<h3 class="dontend" id="toc0"> <a href="#toc0" title="Jump to this section." > Context / intro <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>As a statement about software interactions, a LLM-based platform can: measure, predict, recommend, create (I am roughly quoting a lecture by OSDC pulled from Youtube).   The basic approach has different levels of ability at each behaviour.  Some hype by an AI company <sup><a href="https://situational-awareness.ai/from-gpt-4-to-agi/" target="_blank">1</a></sup> ~ I would be interested in the same output with a constant amount of hardware, to show the software improvements, rather than budget improvements.   Power-scaling notes with good graphs <sup><a href="https://angelxuanchang.github.io/nlp-class/assets/lecture-slides/scaling.pdf" target="_blank">2</a></sup> ~ this is a 50 page PDF &amp; it loads slowly.   To set expectations, learning is not a smooth rate of change in many situations <sup><a href="https://www.fast.ai/posts/2023-09-04-learning-jumps/" target="_blank">3</a></sup> <sup><a href="https://arxiv.org/abs/1712.09913" target="_blank">4</a></sup>.   A systematic review of LLM and handling of them (43 pages) <sup><a href="https://arxiv.org/pdf/2402.06196" target="_blank">5</a></sup>. <br />
When you buy access to an off-the-shelf LLM, it will likely need tuning.   The process to build an LLM is composed of vast amounts of Vector building from source content, but OpenAI seem to use less productisation than I would use.   There are more dedicated and contextual AI, which seems a more valuable route to go along.  Organisations with deep pockets can make their own LLM, but that does seem a very large investment (roughly the same a building your own roads, rather than using the national ones).   According to <sup><a href="https://scalexm.ai/storage/2023/10/White-Paper-LLM.pdf" target="_blank">6</a></sup>, OpenAI have spent over 100,000,000.00 USD on renting cloud servers (this number wasn't given with a timespan).  There is a leaked breakdown <sup><a href="https://medium.com/version-1/running-your-own-dedicated-openai-instance-60a93555dbd0" target="_blank">7</a></sup> with time.   <br />
From a standard LLM, obviously there are a list of techniques that have been developed to improve relevance of the output.   Depending on your AI vendor, these will already be present.   However, an LLM will need configuration to align with your product.   This article is listing hyperparamters but they do not use that term <sup><a href="https://cohere.com/blog/llm-parameters-best-outputs-language-ai" target="_blank">8</a></sup>, referenced as the diagrams are good.  Probably the first technical process is adding <a href="https://owenberesford.me.uk/resource/ai-testing#">unit tests</a> on the LLM, but that is outside of scope for this document.   The outputs can be adjusted by appending to the “known data” for the initial generation, adding a <a href="https://owenberesford.me.uk/resource/ai-retrieval-augmented-generation#">RAG</a> as a parallel data source or thirdly by adjusting the operating context.   I think the first option requires renting your own LLM instance (not cheap) from the LLM vendor.   Or theoretically buying the Vendor (as you are Microsoft) would also work.  <br />
Hopefully it is clear that “prompting” isn't “training” <sup><a href="https://towardsdatascience.com/different-ways-of-training-llms-c57885f388ed" target="_blank">9</a></sup> ~ I adsorbed this from the maths, but want to be clear.  The difference between self-directed learning and directed learning (the second requires a human observer) is important.   <strong>The majority of the technical steps listed above can be downloaded from Pipyi, or Jupyterlabs</strong>, but it's “left as an exercise for the reader” to check that the data-flow lines up with your current iteration.</p>


<h3 class="dontend" id="toc1"> <a href="#toc1" title="Jump to this section." > Techniques to take <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>

<div class="pullout2">
<p>Loud note: this is a fast moving field, old notes published before 2023 do not reflect today's products.   See some nice graphs <sup><a href="https://artificialanalysis.ai/models/gpt-4o-2024-08-06" target="_blank">1</a></sup> .</p>


</div>
<p>There are quite a few algorithms that can be used for tuning (I list 19 in the introduction article), and the tuning process seems to be applicable to any LLM.   I'm not sure if lots of different tuning can be stacked on top of each other (research here?).  The tuning step can deliver:</p>

<ul class="ulbasic">
    <li>The addition of data stored in a different format (e.g. a RAG, or DB results) <sup><a href="https://github.blog/ai-and-ml/llms/customizing-and-fine-tuning-llms-what-you-need-to-know/" target="_blank">1</a></sup> <sup><a href="https://www.acorn.io/resources/learning-center/fine-tuning-llm" target="_blank">2</a></sup> <sup><a href="https://deepchecks.com/how-to-test-llm-applications-before-releasing-to-production/" target="_blank">3</a></sup>.  This improves the results.</li>
    <li>Changing the LLM storage so the LLM will fit on a smaller device e.g. the 4bit quantisation ~ <i>although this example has loss of precision</i>.</li>
    <li>Retraining the LLM to value an extra set of data, absent from the first number crunching (e.g. data after 2021).</li>
    <li>[By non-defined process] splitting the LLM into different 'experts' of a narrower domain <sup><a href="https://developer.nvidia.com/blog/applying-mixture-of-experts-in-llm-architectures/" target="_blank">4</a></sup>, look at Mixtral in Huggingface <sup><a href="https://huggingface.co/docs/transformers/model_doc/mixtral" target="_blank">5</a></sup>.  Possibly the most practical method to train your own LLM from scratch, so choosing the initial data sets.   <i>TODO: find out</i>.</li>
    <li>Applying Attention analysis so the output makes mores sense <sup><a href="https://medium.com/@malachy.moran/llm-reading-list-understanding-attention-is-all-you-need-part-i-4cba140bd541" target="_blank">6</a></sup> <sup><a href="https://medium.com/@harikapanuganty/from-words-to-vectors-inside-the-llm-transformer-architecture-50275c354bc4" target="_blank">7</a></sup> and will probably be present by default.   </li>
    <li>Having a strong Natural-Language-Processing process for step 0, therefore making everything <i>afterwards</i> less like dumb data, and more like structured information.  </li>
    <li>Applying Natural-Language-Processing [1] to generate a more abstract “context prompt” to go with the users prompt, so the LLM has a better prompt to work with (this is a version of Step back prompting).</li>
    <li>Setting the Temperature value carefully, with large amounts of testing.</li>
    <li>Given “assembled” agents / LLM, there is now a stable way to integrate the results <sup><a href="https://huggingface.co/blog/mlabonne/merge-models" target="_blank">8</a></sup>.</li>
    <li>All the above steps, with careful testing.</li>
    <li>For any type of B2B product, and many types of B2C where damage is possible such as Medicine, following a damage-avoiding strategy is essential e.g. <sup><a href="https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext" target="_blank">9</a></sup> </li>
    <li>There should be some sort of specific expert for basic arithmetic operations, maybe using a regex to detect the “answer this basic sum” question, reference some nice graph I saw of social media but don't have a proper reference for (against chat GPT 4o, August edition).</li>
    <li>MAYBE DELETE Embeddings aren't a topic on the rest of this article, however <sup><a href="https://datasciencedojo.com/blog/embeddings-and-llm/" target="_blank">10</a></sup>.</li>
</ul>


</div>
<br /><hr /><br />
<div class="lotsOfWords">
<p>Note mobiles have had “generate the next word in a text/SMS” for a long time, and they achieved this initially on very sparse hardware.   Siri by Apple inc uses a remote voice-clip to text process, but again have been running this for many years.   These are examples of simple and narrow “AI”, that people don't notice.   Whilst I was trying to work out how to tune an LLM, I pulled up the following intro references: an obvious long list of business sectors that could use a tuned LLM <sup><a href="https://www.turing.com/resources/finetuning-large-language-models" target="_blank">1</a></sup>.   For people with no experience building integrations, this <sup><a href="https://writer.com/blog/how-to-evaluate-generative-ai-llm-vendors/" target="_blank">2</a></sup> covers the administration needed to build a successful business process, although it is formatted to fit in power point slides.  <br />
Apple have released a proper OSS LLM (that is, it includes its source data) <sup><a href="https://machinelearning.apple.com/research/openelm" target="_blank">3</a></sup> <sup><a href="https://arxiv.org/html/2404.14619v2" target="_blank">4</a></sup> <sup><a href="https://venturebeat.com/ai/apple-shows-off-open-ai-prowess-new-models-outperform-mistral-and-hugging-face-offerings/" target="_blank">5</a></sup> <a href="https://huggingface.co/collections/apple/core-ml-gallery-models-666b66ca4e6657b7d179bc42" target="_blank">src</a>.   A second OSS LLM library <sup><a href="https://llm.datasette.io/en/stable/" target="_blank">6</a></sup> (This second one doesn't have data attached).   List some processes that people have used to tune an LLM <sup><a href="https://arxiv.org/html/2408.13296v1" target="_blank">7</a></sup>.   Feature generation <sup><a href="https://arxiv.org/pdf/2406.03505" target="_blank">8</a></sup>.</p>

<p>I have made software that will emit a random response a percentage of the time, from a fixed list of options, to make it less dull to use.  This is NOT AI but better UX, and increases delight in tired people.   If you take the title “prompt engineer”, I think some learning in Psychology is important.</p>

<hr />
<p>[1] NLP is sometimes 'natural language programming', 'natural language processing' and 'natural language parsing', but these are covering the same area.</p>


<h3 class="dontend" id="toc2"> <a href="#toc2" title="Jump to this section." > Value prop  <sup><i class="fa fa-link invert" aria-label="Jump this to this section." aria-hidden="true"></i></sup> </a></h3>
<p>A tuned LLM will create the appropriate content a much higher percentage of the time, and is likely to use less hardware resources.  This means it is a better product.  Compared to a base 3rd party LLM, your tuned one may add more features, and deliver better.  Tuning can reduce your hardware requirements, so reduce [excessive for OpenAI] running costs.<br />
An LLM trained for translation <sup><a href="https://arxiv.org/pdf/2302.09210" target="_blank">9</a></sup> as an example of derived value.</p>


</div>
<br /><br />
</div>
    </article>
   </main>
	<div id="contentGroup" class="adjacentGroup" data-group="engineering" title="Use the first link to get the complete range of the group." > <p>Some similar articles in engineering </p>
<div id="groupengineering" class="adjacentList"><a class="adjacentItem button" href="/resource/group-XXX?first=engineering" aria-label="This article lists all items in engineering group.">All of <br />engineering<br /> articles </a> <noscript>Seeing this means the Adjacent feature is <strong>disabled</strong><br /> Try the full page link on the left </noscript></div>
 </div>

  </div>
  <fieldset class="outer_menu articleHeader">
	<legend></legend>
	<nav>
		<div id="navBar" class="row">
			<div class="column">
				<div class="top-bar fullWidth">
					<header><h1>Tune and Improve LLM</h1></header>
			    	<p role="status" class="bigScreenOnly">    </p>
				</div>
				<div id="shareGroup" class="bibbles row addReading">
					<span class="allButtons"> 
						<a id="siteChartLink" class="button smallScreenOnly" href="/resource/site-chart" title="open a webpage of what articles this site holds.">Sitemap</a>
						<a id="rssLink" href="https://owenberesford.me.uk/resource/rss" title="Access the sites RSS feed."> <i class="fa fa-rss" aria-label="Open the RSS for this site." aria-hidden="true"></i><span class="sr-only">RSS</span></a> 
						<span class="button smallScreenOnly" id="shareMenuTrigger" rel="nofollow" aria-haspopup="menu" > Share </span>
						<span class="bigScreenOnly">Share: </span>
                        <a href="https://twitter.com/intent/tweet?text=I+think+this+is+important+https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" title="Share this resource on your twitter account." target="_blank" class="bigScreenOnly"> <i class="fa fa-twitter" aria-label="Share this resource on your twitter account." aria-hidden="true"><span class="sr-only">Twitter</span> </i></a>
						<a href="#" id="mastoTrigger" class="masto bigScreenOnly" title="Share this article with *your* mastodon instance" aria-haspopup="dialog" >	<i class="fa fa-mastodon" aria-label="Share this article on *your* mastodon instance." aria-hidden="true"></i><span class="sr-only">Mastodon</span> </a>

						<a href="https://www.reddit.com/submit?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" target="_blank" title="Share this article with your Reddit audience" class="bigScreenOnly" ><i aria-label="Share this article with your Reddit audience." class="fa fa-reddit-square" aria-hidden="true"></i><span class="sr-only">Reddit </span> </a>
						<a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" target="_blank" class="bigScreenOnly" title="Share current article with your linked-in audience." ><i class="fa fa-linkedin-square" aria-hidden="true" aria-label="Share this article with your linked-in audience."></i><span class="sr-only">Linkedin</span> </a>
						<a title="Share current article with Hacker news/ Y combinator audience" target="_blank" class="bigScreenOnly" href="http://news.ycombinator.com/submitlink?u=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm&amp;t=Tune+LLM"> <i class="fa fa-hacker-news" aria-label="Share this article with your Y combinator audience." aria-hidden="true"> </i><span class="sr-only">Hacker new</span> </a>

						<a title="Share this article with your Xing audience." href="https://www.xing.com/spi/shares/new?url=https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" target="_blank" class="bigScreenOnly" ><i class="fa fa-xing-square" aria-hidden="true" aria-label="Share this article with your Xing audience."></i><span class="sr-only">Xing</span> </a>
					</span>

					<span class="ultraSkinny bigScreenOnly"> 
						<span>Edited <time datetime="2024-10-07T21:38:42">7th of Oct 2024</time>
						</span>
						<span>Created <time datetime="2024-09-14T00:00:00" title="If the value says 03-03-2015; its wrong but that is when this project was moved to the current git project" >14th of Sep 2024</time> </span>
					</span>

				</div>
			</div>
			<dialog id="popup" class="popup1 bigScreenOnly">
				<form method="dialog" encoding="multipart/form-data" action="." name="mastoSelection"  >
					<label for="mastodonserver">your server: 
						<input id="mastodonserver" max-length="50" data-url="https%3A%2F%2Fowenberesford.me.uk%2Fresource%2Fai-tune-llm" type="text" value="" placeholder="mastodon.social" />  
					</label> 
					<span id="sendMasto" class="button masto" title="Share article to *your* mastodon server">Share article now</span>
					<span class="button trimmed" id="hideMasto" title="Close popup"> <i class="fa fa-cancel" aria-hidden="true"></i> Cancel </span>
				</form>
			</dialog>

<fieldset class="h4_menu column bigScreenOnly ">
<legend><span id="pageMenu" aria-haspopup="menu"><i class="fa fa-ob1burger" aria-hidden="true"></i><span class="sr-only">Menu</span> </span></legend>
<menu class="h4_lean">
<li class="h4_odd"><a href="#toc0">Context / intro</a></li>
<li><a href="#toc1">Techniques to take</a></li>
<li class="h4_odd"><a href="#toc2">Value prop</a></li>
</menu>
<br />

</fieldset>
	</div>
<menu class="burgerMenu" >
<li class="h4_odd">Additional features</li>
<li class=""><a href="/resource/home"><i class="fa fa-angle-left" aria-hidden="true"></i> Home</a> </li> 
<li class="h4_odd"><a href="/resource/search">Search <i class="fa fa-angle-right" aria-hidden="true"></i></a></li>
<li class=""><a href="/resource/appearance">Appearance <i class="fa fa-angle-right" aria-hidden="true"></i></a></li>
<li class="h4_odd"><a href="/resource/contact-me">Contact me <i class="fa fa-angle-right" aria-hidden="true"></i></a></li>
<li class=""><a href="#contentGroup">Similar articles</a></li>
</menu>
	</nav>
</fieldset>
		</div>
 <br class="blocker" />
 <div id="biblio" style="display:none;">
    <br class="blocker" />
 </div>
 
 <footer>
  <div class="h4_footer"> 
	<div class="leftFooter"> 
		<a href="https://www.plainenglish.co.uk/services.html" target="_blank" title="They, er, don't have a service for >200,000 word sites, so no logo.">Campaign for Plain English</a><br />
		My profile: <a href="https://www.linkedin.com/in/owen-beresford-bb6ab030/" target="_blank" aria-label="my linked-in" title="Load my linked-in profile" ><i class="fixLinkedSq fa fa-linkedin-square" aria-hidden="true" aria-label="Open my linked in profile" ></i><span class="sr-only">linkedin</span></a> ~ <abbr title="This content wasn't covered in my education, as it didn't exist at that point.">Young tech</abbr>
	</div> 
	<p> Page rendered <time datetime="2024-10-07T22:20:59">7th of Oct 2024, 22:20:59</time>, Copyright &copy; 2022 Owen Beresford, <a href="https://owenberesford.me.uk/resource/contact-me">contact me</a>.  Last modified <time datetime="2024-10-07T21:38:42">7th of Oct 2024</time>.
    <p>Read the generous <a rel="license" href="https://owenberesford.me.uk/resource/licence" title="Load the license term; but not that interesting">licence terms</a>, if you feel the need, there is a <a href="https://owenberesford.me.uk/resource/privacy#" title="Load the privacy terms" >privacy here</a>.    View the <a href="https://owenberesford.me.uk/resource/site-chart#" title="Load a page showing all the articles on this site">site map</a>.  <a href="#pageMenu">Jump to menu</a>
</div>
</footer>
<script type="module" src="/asset/ob1-202406.min.mjs" ></script>

</body>
</html>